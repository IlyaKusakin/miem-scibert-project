{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "mdGQbXBBhT4Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa9c96a8-0c0f-4bbc-e3fd-9f70eefa846a"
      },
      "id": "mdGQbXBBhT4Y",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.5.18.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenizer and linguistic model download"
      ],
      "metadata": {
        "id": "P8QU7GXH9jCq"
      },
      "id": "P8QU7GXH9jCq"
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, BertForMaskedLM\n",
        "import torch\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('miemBertProject/miem-scibert-linguistic')\n",
        "model = BertForMaskedLM.from_pretrained('miemBertProject/miem-scibert-linguistic')"
      ],
      "metadata": {
        "id": "1SeYsVqJ9rFV"
      },
      "id": "1SeYsVqJ9rFV",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set input sentence for model and mask token #11 (\"риса\")"
      ],
      "metadata": {
        "id": "Cai0GHVA9sBw"
      },
      "id": "Cai0GHVA9sBw"
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = tokenizer(\"Сравнительное влияние климата и обновления культивации на урожайность риса в Китае\", return_tensors=\"pt\")[\"input_ids\"]\n",
        "idx_to_predict=11\n",
        "input_ids[0,idx_to_predict]=tokenizer.mask_token_id"
      ],
      "metadata": {
        "id": "DoPMz9Ck-MIn"
      },
      "id": "DoPMz9Ck-MIn",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pass through the model to predict masked token"
      ],
      "metadata": {
        "id": "t6fqpuZa-ONu"
      },
      "id": "t6fqpuZa-ONu"
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    outputs = model(input_ids, labels=input_ids)\n",
        "    loss, prediction_scores = outputs[:2]\n",
        "predicted_index = torch.argmax(prediction_scores[0][idx_to_predict]).item()\n",
        "predicted_token = tokenizer.convert_ids_to_tokens([predicted_index])"
      ],
      "metadata": {
        "id": "eyNLcSKGg3wl"
      },
      "id": "eyNLcSKGg3wl",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predicted token"
      ],
      "metadata": {
        "id": "tNOPPdnA-dIs"
      },
      "id": "tNOPPdnA-dIs"
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_token,tokenizer.convert_ids_to_tokens([tokenizer(\"Сравнительное влияние климата и обновления культивации на урожайность риса в Китае\", return_tensors=\"pt\")[\"input_ids\"][0,idx_to_predict]])"
      ],
      "metadata": {
        "id": "Al-ZKkAphuMd",
        "outputId": "c3e2df9e-4f59-4b12-a609-c53c3047ad2a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "Al-ZKkAphuMd",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['риса'], ['риса'])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get text embedding via miem-scibert-linguistic"
      ],
      "metadata": {
        "id": "zEzG7H4_-nXz"
      },
      "id": "zEzG7H4_-nXz"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "4ff04f6b",
      "metadata": {
        "id": "4ff04f6b",
        "outputId": "6641b371-f930-4891-96e5-a415eda62c47",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at miemBertProject/miem-scibert-linguistic were not used when initializing BertModel: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertModel were not initialized from the model checkpoint at miemBertProject/miem-scibert-linguistic and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertModel\n",
        "model=BertModel.from_pretrained('miemBertProject/miem-scibert-linguistic')\n",
        "model.eval()\n",
        "input_ids = tokenizer(\"Сравнительное влияние климата и обновления культивации на урожайность риса в Китае\", return_tensors=\"pt\")[\"input_ids\"]\n",
        "outputs=model(input_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "a1d906fb",
      "metadata": {
        "id": "a1d906fb",
        "outputId": "d88127fb-2c28-41aa-eb9a-e178dd04f7dd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 15, 768]), torch.Size([1, 768]))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "outputs[0].shape, outputs[1].shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs[0]~[Number of texts in batch; number of tokens in text; hidden size=768] Tokens embeddings\n",
        "outputs[1]~[Number of texts in batch; hidden size=768] Text embedding "
      ],
      "metadata": {
        "id": "4vV-ChI0-436"
      },
      "id": "4vV-ChI0-436",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b43361a1",
      "metadata": {
        "id": "b43361a1"
      },
      "outputs": [],
      "source": [
        "outputs[0]~[Количество текстов в баче; Количество токенов в тексте; Размер скрытого пространства=768] Эмбеддинги токенов\n",
        "outputs[1]~[Количество текстов в баче; Размер скрытого пространства=768] Эмбеддинг текста"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "scibert_ru_usage.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}